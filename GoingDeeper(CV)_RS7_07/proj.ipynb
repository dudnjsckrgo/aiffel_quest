{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/aiffel/aiffel_quest/GoingDeeper(CV)_RS7_07\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIDER_test:\n",
      "\u001b[0m\u001b[01;34mWIDER_test\u001b[0m/\n",
      "\n",
      "WIDER_train:\n",
      "\u001b[01;34mWIDER_train\u001b[0m/\n",
      "\n",
      "WIDER_val:\n",
      "\u001b[01;34mWIDER_val\u001b[0m/\n",
      "\n",
      "wider_face_split:\n",
      "\u001b[01;34mwider_face_split\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "ls wider_face_split  WIDER_test  WIDER_train  WIDER_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'wider_face_split/wider_face_train_bbx_gt.txt' for reading: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!head -20 wider_face_split/wider_face_train_bbx_gt.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 20:44:54.460507: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-24 20:44:54.486767: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-24 20:44:54.486783: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-24 20:44:54.487345: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-24 20:44:54.491181: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import os, cv2, time\n",
    "import tensorflow as tf\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "PROJECT_PATH = '/tf/aiffel/aiffel_quest/GoingDeeper(CV)_RS7_07'\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'widerface')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
    "TRAIN_TFRECORD_PATH = os.path.join(PROJECT_PATH, 'dataset', 'train_mask.tfrecord')\n",
    "VALID_TFRECORD_PATH = os.path.join(PROJECT_PATH, 'dataset', 'val_mask.tfrecord')\n",
    "CHECKPOINT_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
    "\n",
    "DATASET_LEN = 12880\n",
    "BATCH_SIZE = 32\n",
    "IMAGE_WIDTH = 320\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_LABELS = ['background', 'face']\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_box(data):\n",
    "    x0 = int(data[0])\n",
    "    y0 = int(data[1])\n",
    "    w = int(data[2])\n",
    "    h = int(data[3])\n",
    "    return x0, y0, w, h\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_widerface(file):\n",
    "    infos = []\n",
    "    with open(file) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            n_object = int(fp.readline())\n",
    "            boxes = []\n",
    "            for i in range(n_object):\n",
    "                box = fp.readline().split(' ')\n",
    "                x0, y0, w, h = parse_box(box)\n",
    "                if (w == 0) or (h == 0):\n",
    "                    continue\n",
    "                boxes.append([x0, y0, w, h])\n",
    "            if n_object == 0:\n",
    "                box = fp.readline().split(' ')\n",
    "                x0, y0, w, h = parse_box(box)\n",
    "                boxes.append([x0, y0, w, h])\n",
    "            infos.append((line.strip(), boxes))\n",
    "            line = fp.readline()\n",
    "    return infos\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def process_image(image_file):\n",
    "    image_string = tf.io.read_file(image_file)\n",
    "    try:\n",
    "        image_data = tf.image.decode_jpeg(image_string, channels=3)\n",
    "        return 0, image_string, image_data\n",
    "    except tf.errors.InvalidArgumentError:\n",
    "        return 1, image_string, None\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def xywh_to_voc(file_name, boxes, image_data):\n",
    "    shape = image_data.shape\n",
    "    image_info = {}\n",
    "    image_info['filename'] = file_name\n",
    "    image_info['width'] = shape[1]\n",
    "    image_info['height'] = shape[0]\n",
    "    image_info['depth'] = 3\n",
    "\n",
    "    difficult = []\n",
    "    classes = []\n",
    "    xmin, ymin, xmax, ymax = [], [], [], []\n",
    "\n",
    "    for box in boxes:\n",
    "        classes.append(1)\n",
    "        difficult.append(0)\n",
    "        xmin.append(box[0])\n",
    "        ymin.append(box[1])\n",
    "        xmax.append(box[0] + box[2])\n",
    "        ymax.append(box[1] + box[3])\n",
    "    image_info['class'] = classes\n",
    "    image_info['xmin'] = xmin\n",
    "    image_info['ymin'] = ymin\n",
    "    image_info['xmax'] = xmax\n",
    "    image_info['ymax'] = ymax\n",
    "    image_info['difficult'] = difficult\n",
    "\n",
    "    return image_info\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'filename': '/tf/aiffel/aiffel_quest/GoingDeeper(CV)_RS7_07/widerface/WIDER_train/images/0--Parade/0_Parade_marchingband_1_849.jpg', 'width': 1024, 'height': 1385, 'depth': 3, 'class': [1], 'xmin': [449], 'ymin': [330], 'xmax': [571], 'ymax': [479], 'difficult': [0]}\n",
      "--------------------\n",
      "{'filename': '/tf/aiffel/aiffel_quest/GoingDeeper(CV)_RS7_07/widerface/WIDER_train/images/0--Parade/0_Parade_Parade_0_904.jpg', 'width': 1024, 'height': 1432, 'depth': 3, 'class': [1], 'xmin': [361], 'ymin': [98], 'xmax': [624], 'ymax': [437], 'difficult': [0]}\n",
      "--------------------\n",
      "{'filename': '/tf/aiffel/aiffel_quest/GoingDeeper(CV)_RS7_07/widerface/WIDER_train/images/0--Parade/0_Parade_marchingband_1_799.jpg', 'width': 1024, 'height': 768, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [78, 78, 113, 134, 163, 201, 182, 245, 304, 328, 389, 406, 436, 522, 643, 653, 793, 535, 29, 3, 20], 'ymin': [221, 238, 212, 260, 250, 218, 266, 279, 265, 295, 281, 293, 290, 328, 320, 224, 337, 311, 220, 232, 215], 'xmax': [85, 92, 124, 149, 177, 211, 197, 263, 320, 344, 406, 427, 458, 543, 666, 670, 816, 551, 40, 14, 32], 'ymax': [229, 255, 227, 275, 267, 230, 283, 294, 282, 315, 300, 314, 307, 346, 342, 249, 367, 328, 235, 247, 231], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "--------------------\n",
      "{'filename': '/tf/aiffel/aiffel_quest/GoingDeeper(CV)_RS7_07/widerface/WIDER_train/images/0--Parade/0_Parade_marchingband_1_117.jpg', 'width': 1024, 'height': 682, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [69, 227, 296, 353, 885, 819, 727, 598, 740], 'ymin': [359, 382, 305, 280, 377, 391, 342, 246, 308], 'xmax': [119, 283, 340, 393, 948, 853, 764, 631, 785], 'ymax': [395, 425, 331, 316, 418, 434, 373, 275, 341], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "--------------------\n",
      "{'filename': '/tf/aiffel/aiffel_quest/GoingDeeper(CV)_RS7_07/widerface/WIDER_train/images/0--Parade/0_Parade_marchingband_1_778.jpg', 'width': 1024, 'height': 852, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [27, 63, 64, 88, 231, 263, 367, 198, 293, 412, 441, 475, 510, 576, 577, 595, 570, 645, 719, 791, 884, 898, 945, 922, 743, 841, 980, 1001, 488, 586, 669, 744, 803, 294, 203], 'ymin': [226, 95, 63, 13, 1, 122, 68, 98, 161, 36, 23, 40, 23, 30, 71, 94, 126, 171, 98, 154, 97, 48, 89, 38, 71, 18, 56, 107, 2, 1, 1, 2, 3, 2, 0], 'xmax': [60, 79, 81, 104, 244, 277, 382, 213, 345, 426, 458, 489, 524, 592, 593, 611, 583, 697, 730, 845, 900, 913, 960, 937, 754, 857, 993, 1015, 500, 601, 681, 762, 821, 305, 216], 'ymax': [262, 114, 81, 28, 14, 142, 91, 116, 220, 56, 36, 61, 40, 45, 92, 114, 142, 229, 113, 203, 118, 69, 109, 54, 89, 34, 76, 120, 20, 18, 16, 17, 20, 12, 14], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-24 20:44:58.877110: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:274] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-01-24 20:44:58.877126: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:129] retrieving CUDA diagnostic information for host: 3d1b0084c99c\n",
      "2024-01-24 20:44:58.877128: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:136] hostname: 3d1b0084c99c\n",
      "2024-01-24 20:44:58.877161: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:159] libcuda reported version is: 545.23.8\n",
      "2024-01-24 20:44:58.877171: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:163] kernel reported version is: 545.23.8\n",
      "2024-01-24 20:44:58.877173: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:241] kernel version seems to match DSO: 545.23.8\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(DATA_PATH, 'wider_face_split', 'wider_face_train_bbx_gt.txt')\n",
    "for i, info in enumerate(parse_widerface(file_path)):\n",
    "    print('--------------------')\n",
    "    image_file = os.path.join(DATA_PATH, 'WIDER_train', \"images\", info[0])\n",
    "    _, image_string, image_data = process_image(image_file)\n",
    "    boxes = xywh_to_voc(image_file, info[1], image_data)\n",
    "    print(boxes)\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def make_example(image_string, image_infos):\n",
    "    for info in image_infos:\n",
    "        filename = info['filename']\n",
    "        width = info['width']\n",
    "        height = info['height']\n",
    "        depth = info['depth']\n",
    "        classes = info['class']\n",
    "        xmin = info['xmin']\n",
    "        ymin = info['ymin']\n",
    "        xmax = info['xmax']\n",
    "        ymax = info['ymax']\n",
    "\n",
    "    if isinstance(image_string, type(tf.constant(0))):\n",
    "        encoded_image = [image_string.numpy()]\n",
    "    else:\n",
    "        encoded_image = [image_string]\n",
    "\n",
    "    base_name = [tf.compat.as_bytes(os.path.basename(filename))]\n",
    "    \n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'filename':tf.train.Feature(bytes_list=tf.train.BytesList(value=base_name)),\n",
    "        'height':tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'width':tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'classes':tf.train.Feature(int64_list=tf.train.Int64List(value=classes)),\n",
    "        'x_mins':tf.train.Feature(float_list=tf.train.FloatList(value=xmin)),\n",
    "        'y_mins':tf.train.Feature(float_list=tf.train.FloatList(value=ymin)),\n",
    "        'x_maxes':tf.train.Feature(float_list=tf.train.FloatList(value=xmax)),\n",
    "        'y_maxes':tf.train.Feature(float_list=tf.train.FloatList(value=ymax)),\n",
    "        'image_raw':tf.train.Feature(bytes_list=tf.train.BytesList(value=encoded_image))\n",
    "    }))\n",
    "    \n",
    "    return example\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12880/12880 [00:32<00:00, 390.98it/s]\n",
      "100%|██████████| 3226/3226 [00:08<00:00, 388.52it/s]\n"
     ]
    }
   ],
   "source": [
    "for split in ['train', 'val']:\n",
    "    if split == 'train':\n",
    "        output_file = TRAIN_TFRECORD_PATH \n",
    "        anno_txt = 'wider_face_train_bbx_gt.txt'\n",
    "        file_path = 'WIDER_train'\n",
    "    else:\n",
    "        output_file = VALID_TFRECORD_PATH\n",
    "        anno_txt = 'wider_face_val_bbx_gt.txt'\n",
    "        file_path = 'WIDER_val'\n",
    "\n",
    "    with tf.io.TFRecordWriter(output_file) as writer:\n",
    "        for info in tqdm.tqdm(parse_widerface(os.path.join(DATA_PATH, 'wider_face_split', anno_txt))):\n",
    "            image_file = os.path.join(DATA_PATH, file_path, 'images', info[0])\n",
    "            error, image_string, image_data = process_image(image_file)\n",
    "            boxes = xywh_to_voc(image_file, info[1], image_data)\n",
    "\n",
    "            if not error:\n",
    "                tf_example = make_example(image_string, [boxes])\n",
    "                writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ~/aiffel/face_detector/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "BOX_MIN_SIZES = [[10, 16, 24], [32, 48], [64, 96], [128, 192, 256]]\n",
    "BOX_STEPS = [8, 16, 32, 64]\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[32, 40], [16, 20], [8, 10], [4, 5]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_sizes = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "min_sizes = BOX_MIN_SIZES\n",
    "steps= BOX_STEPS\n",
    "\n",
    "feature_maps = [\n",
    "    [math.ceil(image_sizes[0] / step), math.ceil(image_sizes[1] / step)]\n",
    "    for step in steps\n",
    "]\n",
    "feature_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18800"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxes = []\n",
    "for k, f in enumerate(feature_maps):\n",
    "    for i, j in product(range(f[0]), range(f[1])):\n",
    "        for min_size in min_sizes[k]:\n",
    "            s_kx = min_size / image_sizes[1]\n",
    "            s_ky = min_size / image_sizes[0]\n",
    "            cx = (j + 0.5) * steps[k] / image_sizes[1]\n",
    "            cy = (i + 0.5) * steps[k] / image_sizes[0]\n",
    "            boxes += [cx, cy, s_kx, s_ky]\n",
    "\n",
    "len(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4700, 4)\n",
      "[[0.0125    0.015625  0.03125   0.0390625]\n",
      " [0.0125    0.015625  0.05      0.0625   ]\n",
      " [0.0125    0.015625  0.075     0.09375  ]\n",
      " ...\n",
      " [0.9       0.875     0.4       0.5      ]\n",
      " [0.9       0.875     0.6       0.75     ]\n",
      " [0.9       0.875     0.8       1.       ]]\n"
     ]
    }
   ],
   "source": [
    "pretty_boxes = np.asarray(boxes).reshape([-1, 4])\n",
    "print(pretty_boxes.shape)\n",
    "print(pretty_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_box():\n",
    "    image_sizes = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    min_sizes = BOX_MIN_SIZES\n",
    "    steps= BOX_STEPS\n",
    "    feature_maps = [\n",
    "        [math.ceil(image_sizes[0] / step), math.ceil(image_sizes[1] / step)]\n",
    "        for step in steps\n",
    "    ]\n",
    "    boxes = []\n",
    "    for k, f in enumerate(feature_maps):\n",
    "        for i, j in product(range(f[0]), range(f[1])):\n",
    "            for min_size in min_sizes[k]:\n",
    "                s_kx = min_size / image_sizes[1]\n",
    "                s_ky = min_size / image_sizes[0]\n",
    "                cx = (j + 0.5) * steps[k] / image_sizes[1]\n",
    "                cy = (i + 0.5) * steps[k] / image_sizes[0]\n",
    "                boxes += [cx, cy, s_kx, s_ky]\n",
    "    boxes = np.asarray(boxes).reshape([-1, 4])\n",
    "    return boxes\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _conv_block(inputs, filters, kernel=(3, 3), strides=(1, 1)):\n",
    "    block_id = (tf.keras.backend.get_uid())\n",
    "    if strides == (2, 2):\n",
    "        x = tf.keras.layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='conv_pad_%d' % block_id)(inputs)\n",
    "        x = tf.keras.layers.Conv2D(filters, kernel,\n",
    "                                   padding='valid',\n",
    "                                   use_bias=False,\n",
    "                                   strides=strides,\n",
    "                                   name='conv_%d' % block_id)(x)\n",
    "    else:\n",
    "        x = tf.keras.layers.Conv2D(filters, kernel,\n",
    "                                   padding='same',\n",
    "                                   use_bias=False,\n",
    "                                   strides=strides,\n",
    "                                   name='conv_%d' % block_id)(inputs)\n",
    "    \n",
    "    x = tf.keras.layers.BatchNormalization(name='conv_bn_%d' % block_id)(x)\n",
    "    return tf.keras.layers.ReLU(name='conv_relu_%d' % block_id)(x)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _depthwise_conv_block(inputs, filters, strides=(1, 1)):\n",
    "    block_id = tf.keras.backend.get_uid()\n",
    "    if strides == (1, 1):\n",
    "        x = inputs\n",
    "    else:\n",
    "        x = tf.keras.layers.ZeroPadding2D(((1, 1), (1, 1)), name='conv_pad_%d' % block_id)(inputs)\n",
    "    x = tf.keras.layers.DepthwiseConv2D((3, 3),\n",
    "                                        padding='same' if strides == (1, 1) else 'valid',\n",
    "                                        strides=strides,\n",
    "                                        use_bias=False,\n",
    "                                        name='conv_dw_%d' % block_id)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='conv_dw_%d_bn' % block_id)(x)\n",
    "    x = tf.keras.layers.ReLU(name='conv_dw_%d_relu' % block_id)(x)\n",
    "    x = tf.keras.layers.Conv2D(filters, (1, 1),\n",
    "                               padding='same',\n",
    "                               use_bias=False,\n",
    "                               strides=(1, 1),\n",
    "                               name='conv_pw_%d' % block_id)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(name='conv_pw_%d_bn' % block_id)(x)\n",
    "    return tf.keras.layers.ReLU(name='conv_pw_%d_relu' % block_id)(x)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _branch_block(inputs, filters):\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = tf.keras.layers.LeakyReLU()(x)\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), padding='same')(x)\n",
    "    x1 = tf.keras.layers.Conv2D(filters * 2, kernel_size=(3, 3), padding='same')(inputs)\n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([x, x1])\n",
    "    return tf.keras.layers.ReLU()(x)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_head_block(inputs, filters):\n",
    "    x = tf.keras.layers.Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    return x\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_heads(inputs, num_class, num_cell):\n",
    "    conf = _create_head_block(inputs, num_cell * num_class)\n",
    "    conf = tf.keras.layers.Reshape((-1, num_class))(conf)\n",
    "    loc = _create_head_block(inputs, num_cell * 4)\n",
    "    loc = tf.keras.layers.Reshape((-1, 4))(loc)\n",
    "    return conf, loc\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SsdModel():\n",
    "    base_channel = 16\n",
    "    num_cells = [3, 2, 2, 3]\n",
    "    num_class = len(IMAGE_LABELS)\n",
    "    \n",
    "    x = inputs = tf.keras.layers.Input(shape=[IMAGE_HEIGHT, IMAGE_WIDTH, 3], name='input_image')\n",
    "\n",
    "    x = _conv_block(x, base_channel, strides=(2, 2))\n",
    "    x = _conv_block(x, base_channel * 2, strides=(1, 1))\n",
    "    x = _conv_block(x, base_channel * 2, strides=(2, 2))\n",
    "    x = _conv_block(x, base_channel * 2, strides=(1, 1))\n",
    "    x = _conv_block(x, base_channel * 4, strides=(2, 2))\n",
    "    x = _conv_block(x, base_channel * 4, strides=(1, 1))\n",
    "    x = _conv_block(x, base_channel * 4, strides=(1, 1))\n",
    "    x = _conv_block(x, base_channel * 4, strides=(1, 1))\n",
    "    x1 = _branch_block(x, base_channel)\n",
    "\n",
    "    x = _conv_block(x, base_channel * 8, strides=(2, 2))\n",
    "    x = _conv_block(x, base_channel * 8, strides=(1, 1))\n",
    "    x = _conv_block(x, base_channel * 8, strides=(1, 1))\n",
    "    x2 = _branch_block(x, base_channel)\n",
    "\n",
    "    x = _depthwise_conv_block(x, base_channel * 16, strides=(2, 2))\n",
    "    x = _depthwise_conv_block(x, base_channel * 16, strides=(1, 1))\n",
    "    x3 = _branch_block(x, base_channel)\n",
    "\n",
    "    x = _depthwise_conv_block(x, base_channel * 16, strides=(2, 2))\n",
    "    x4 = _branch_block(x, base_channel)\n",
    "\n",
    "    extra_layers = [x1, x2, x3, x4]\n",
    "\n",
    "    confs = []\n",
    "    locs = []\n",
    "\n",
    "    for layer, num_cell in zip(extra_layers, num_cells):\n",
    "        conf, loc = _compute_heads(layer, num_class, num_cell)\n",
    "        confs.append(conf)\n",
    "        locs.append(loc)\n",
    "\n",
    "    confs = tf.keras.layers.Concatenate(axis=1, name=\"face_classes\")(confs)\n",
    "    locs = tf.keras.layers.Concatenate(axis=1, name=\"face_boxes\")(locs)\n",
    "\n",
    "    predictions = tf.keras.layers.Concatenate(axis=2, name='predictions')([locs, confs])\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=predictions, name='ssd_model')\n",
    "    return model\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SsdModel()\n",
    "print(\"the number of model layers: \", len(model.layers))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _crop(img, labels, max_loop=250):\n",
    "    shape = tf.shape(img)\n",
    "\n",
    "    def matrix_iof(a, b):\n",
    "        lt = tf.math.maximum(a[:, tf.newaxis, :2], b[:, :2])\n",
    "        rb = tf.math.minimum(a[:, tf.newaxis, 2:], b[:, 2:])\n",
    "\n",
    "        area_i = tf.math.reduce_prod(rb - lt, axis=2) * \\\n",
    "            tf.cast(tf.reduce_all(lt < rb, axis=2), tf.float32)\n",
    "        area_a = tf.math.reduce_prod(a[:, 2:] - a[:, :2], axis=1)\n",
    "        return area_i / tf.math.maximum(area_a[:, tf.newaxis], 1)\n",
    "\n",
    "    def crop_loop_body(i, img, labels):\n",
    "        valid_crop = tf.constant(1, tf.int32)\n",
    "\n",
    "        pre_scale = tf.constant([0.3, 0.45, 0.6, 0.8, 1.0], dtype=tf.float32)\n",
    "        scale = pre_scale[tf.random.uniform([], 0, 5, dtype=tf.int32)]\n",
    "        short_side = tf.cast(tf.minimum(shape[0], shape[1]), tf.float32)\n",
    "        h = w = tf.cast(scale * short_side, tf.int32)\n",
    "        h_offset = tf.random.uniform([], 0, shape[0] - h + 1, dtype=tf.int32)\n",
    "        w_offset = tf.random.uniform([], 0, shape[1] - w + 1, dtype=tf.int32)\n",
    "        roi = tf.stack([w_offset, h_offset, w_offset + w, h_offset + h])\n",
    "        roi = tf.cast(roi, tf.float32)\n",
    "\n",
    "        value = matrix_iof(labels[:, :4], roi[tf.newaxis])\n",
    "        valid_crop = tf.cond(tf.math.reduce_any(value >= 1),\n",
    "                             lambda: valid_crop, lambda: 0)\n",
    "\n",
    "        centers = (labels[:, :2] + labels[:, 2:4]) / 2\n",
    "        mask_a = tf.reduce_all(\n",
    "            tf.math.logical_and(roi[:2] < centers, centers < roi[2:]),\n",
    "            axis=1)\n",
    "        labels_t = tf.boolean_mask(labels, mask_a)\n",
    "        valid_crop = tf.cond(tf.reduce_any(mask_a),\n",
    "                             lambda: valid_crop, lambda: 0)\n",
    "\n",
    "        img_t = img[h_offset:h_offset + h, w_offset:w_offset + w, :]\n",
    "        h_offset = tf.cast(h_offset, tf.float32)\n",
    "        w_offset = tf.cast(w_offset, tf.float32)\n",
    "        labels_t = tf.stack(\n",
    "            [labels_t[:, 0] - w_offset,  labels_t[:, 1] - h_offset,\n",
    "             labels_t[:, 2] - w_offset,  labels_t[:, 3] - h_offset,\n",
    "             labels_t[:, 4]], axis=1)\n",
    "\n",
    "        return tf.cond(valid_crop == 1,\n",
    "                       lambda: (max_loop, img_t, labels_t),\n",
    "                       lambda: (i + 1, img, labels))\n",
    "\n",
    "    _, img, labels = tf.while_loop(\n",
    "        lambda i, img, labels: tf.less(i, max_loop),\n",
    "        crop_loop_body,\n",
    "        [tf.constant(-1), img, labels],\n",
    "        shape_invariants=[tf.TensorShape([]),\n",
    "                          tf.TensorShape([None, None, 3]),\n",
    "                          tf.TensorShape([None, 5])])\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resize(img, labels):\n",
    "    w_f = tf.cast(tf.shape(img)[1], tf.float32)\n",
    "    h_f = tf.cast(tf.shape(img)[0], tf.float32)\n",
    "    locs = tf.stack([labels[:, 0] / w_f,  labels[:, 1] / h_f,\n",
    "                     labels[:, 2] / w_f,  labels[:, 3] / h_f] ,axis=1)\n",
    "    locs = tf.clip_by_value(locs, 0, 1.0)\n",
    "    labels = tf.concat([locs, labels[:, 4][:, tf.newaxis]], axis=1)\n",
    "\n",
    "    resize_case = tf.random.uniform([], 0, 5, dtype=tf.int32)\n",
    "\n",
    "    def resize(method):\n",
    "        def _resize():\n",
    "            #　size h,w\n",
    "            return tf.image.resize(img, [IMAGE_HEIGHT, IMAGE_WIDTH], method=method, antialias=True)\n",
    "        return _resize\n",
    "\n",
    "    img = tf.case([(tf.equal(resize_case, 0), resize('bicubic')),\n",
    "                   (tf.equal(resize_case, 1), resize('area')),\n",
    "                   (tf.equal(resize_case, 2), resize('nearest')),\n",
    "                   (tf.equal(resize_case, 3), resize('lanczos3'))],\n",
    "                  default=resize('bilinear'))\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _flip(img, labels):\n",
    "    flip_case = tf.random.uniform([], 0, 2, dtype=tf.int32)\n",
    "\n",
    "    def flip_func():\n",
    "        flip_img = tf.image.flip_left_right(img)\n",
    "        flip_labels = tf.stack([1 - labels[:, 2],  labels[:, 1],\n",
    "                                1 - labels[:, 0],  labels[:, 3],\n",
    "                                labels[:, 4]], axis=1)\n",
    "\n",
    "        return flip_img, flip_labels\n",
    "\n",
    "    img, labels = tf.case([(tf.equal(flip_case, 0), flip_func)],default=lambda: (img, labels))\n",
    "\n",
    "    return img, labels\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pad_to_square(img):\n",
    "    height = tf.shape(img)[0]\n",
    "    width = tf.shape(img)[1]\n",
    "\n",
    "    def pad_h():\n",
    "        img_pad_h = tf.ones([width - height, width, 3]) * tf.reduce_mean(img, axis=[0, 1], keepdims=True)\n",
    "        return tf.concat([img, img_pad_h], axis=0)\n",
    "\n",
    "    def pad_w():\n",
    "        img_pad_w = tf.ones([height, height - width, 3]) * tf.reduce_mean(img, axis=[0, 1], keepdims=True)\n",
    "        return tf.concat([img, img_pad_w], axis=1)\n",
    "\n",
    "    img = tf.case([(tf.greater(height, width), pad_w),\n",
    "                   (tf.less(height, width), pad_h)], default=lambda: img)\n",
    "    return img\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _distort(img):\n",
    "    img = tf.image.random_brightness(img, 0.4)\n",
    "    img = tf.image.random_contrast(img, 0.5, 1.5)\n",
    "    img = tf.image.random_saturation(img, 0.5, 1.5)\n",
    "    img = tf.image.random_hue(img, 0.1)\n",
    "\n",
    "    return img\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _intersect(box_a, box_b):\n",
    "    A = tf.shape(box_a)[0]\n",
    "    B = tf.shape(box_b)[0]\n",
    "    max_xy = tf.minimum(\n",
    "        tf.broadcast_to(tf.expand_dims(box_a[:, 2:], 1), [A, B, 2]),\n",
    "        tf.broadcast_to(tf.expand_dims(box_b[:, 2:], 0), [A, B, 2]))\n",
    "    min_xy = tf.maximum(\n",
    "        tf.broadcast_to(tf.expand_dims(box_a[:, :2], 1), [A, B, 2]),\n",
    "        tf.broadcast_to(tf.expand_dims(box_b[:, :2], 0), [A, B, 2]))\n",
    "    inter = tf.clip_by_value(max_xy - min_xy, 0.0, 512.0)\n",
    "    return inter[:, :, 0] * inter[:, :, 1]\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _jaccard(box_a, box_b):\n",
    "    inter = _intersect(box_a, box_b)\n",
    "    area_a = tf.broadcast_to(\n",
    "        tf.expand_dims(\n",
    "            (box_a[:, 2] - box_a[:, 0]) * (box_a[:, 3] - box_a[:, 1]), 1),\n",
    "        tf.shape(inter))  # [A,B]\n",
    "    area_b = tf.broadcast_to(\n",
    "        tf.expand_dims(\n",
    "            (box_b[:, 2] - box_b[:, 0]) * (box_b[:, 3] - box_b[:, 1]), 0),\n",
    "        tf.shape(inter))  # [A,B]\n",
    "    union = area_a + area_b - inter\n",
    "    return inter / union  # [A,B]\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encode_bbox(matched, boxes, variances=[0.1, 0.2]):\n",
    "    g_cxcy = (matched[:, :2] + matched[:, 2:]) / 2 - boxes[:, :2]\n",
    "    g_cxcy /= (variances[0] * boxes[:, 2:])\n",
    "    g_wh = (matched[:, 2:] - matched[:, :2]) / boxes[:, 2:]\n",
    "    g_wh = tf.math.log(g_wh) / variances[1]\n",
    "    g_wh = tf.where(tf.math.is_inf(g_wh), 0.0, g_wh)\n",
    "    return tf.concat([g_cxcy, g_wh], 1)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tf(labels, boxes):\n",
    "    match_threshold = 0.45\n",
    "    boxes = tf.cast(boxes, tf.float32)\n",
    "    bbox = labels[:, :4]\n",
    "    conf = labels[:, -1]\n",
    "   \n",
    "    # jaccard index\n",
    "    overlaps = _jaccard(bbox, boxes)\n",
    "    best_box_overlap = tf.reduce_max(overlaps, 1)\n",
    "    best_box_idx = tf.argmax(overlaps, 1, tf.int32)\n",
    "\n",
    "    best_truth_overlap = tf.reduce_max(overlaps, 0)\n",
    "    best_truth_idx = tf.argmax(overlaps, 0, tf.int32)\n",
    "\n",
    "    best_truth_overlap = tf.tensor_scatter_nd_update(\n",
    "        best_truth_overlap, tf.expand_dims(best_box_idx, 1),\n",
    "        tf.ones_like(best_box_idx, tf.float32) * 2.)\n",
    "    best_truth_idx = tf.tensor_scatter_nd_update(\n",
    "        best_truth_idx, tf.expand_dims(best_box_idx, 1),\n",
    "        tf.range(tf.size(best_box_idx), dtype=tf.int32))\n",
    "    # Scale Ground-Truth Boxes   \n",
    "    matches_bbox = tf.gather(bbox, best_truth_idx)\n",
    "    loc_t = _encode_bbox(matches_bbox, boxes)\n",
    "    conf_t = tf.gather(conf, best_truth_idx)\n",
    "    conf_t = tf.where(tf.less(best_truth_overlap, match_threshold), tf.zeros_like(conf_t), conf_t)\n",
    "\n",
    "    return tf.concat([loc_t, conf_t[..., tf.newaxis]], axis=1)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _transform_data(train, boxes):\n",
    "    def transform_data(img, labels):\n",
    "        img = tf.cast(img, tf.float32)\n",
    "        if train:\n",
    "            img, labels = _crop(img, labels)\n",
    "            img = _pad_to_square(img)\n",
    "\n",
    "        img, labels = _resize(img, labels)\n",
    "\n",
    "        if train:\n",
    "            img, labels = _flip(img, labels)\n",
    "\n",
    "        if train:\n",
    "            img = _distort(img)\n",
    "        labels = encode_tf(labels, boxes)        \n",
    "        img = img/255.0\n",
    "        return img, labels\n",
    "    return transform_data\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_tfrecord(train, boxes):\n",
    "    def parse_tfrecord(tfrecord):\n",
    "        features = {\n",
    "            'filename': tf.io.FixedLenFeature([], tf.string),\n",
    "            'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "            'classes': tf.io.VarLenFeature(tf.int64),\n",
    "            'x_mins': tf.io.VarLenFeature(tf.float32),\n",
    "            'y_mins': tf.io.VarLenFeature(tf.float32),\n",
    "            'x_maxes': tf.io.VarLenFeature(tf.float32),\n",
    "            'y_maxes': tf.io.VarLenFeature(tf.float32),\n",
    "            'difficult':tf.io.VarLenFeature(tf.int64),\n",
    "            'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "           }\n",
    "\n",
    "        parsed_example = tf.io.parse_single_example(tfrecord, features)\n",
    "        img = tf.image.decode_jpeg(parsed_example['image_raw'], channels=3)\n",
    "\n",
    "        width = tf.cast(parsed_example['width'], tf.float32)\n",
    "        height = tf.cast(parsed_example['height'], tf.float32)\n",
    "\n",
    "        labels = tf.sparse.to_dense(parsed_example['classes'])\n",
    "        labels = tf.cast(labels, tf.float32)\n",
    "\n",
    "        labels = tf.stack(\n",
    "            [tf.sparse.to_dense(parsed_example['x_mins']),\n",
    "             tf.sparse.to_dense(parsed_example['y_mins']),\n",
    "             tf.sparse.to_dense(parsed_example['x_maxes']),\n",
    "             tf.sparse.to_dense(parsed_example['y_maxes']),labels], axis=1)\n",
    "\n",
    "        img, labels = _transform_data(train, boxes)(img, labels)\n",
    "\n",
    "        return img, labels\n",
    "    return parse_tfrecord\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tfrecord_dataset(tfrecord_name, train=True, boxes=None, buffer_size=1024):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
    "    raw_dataset = raw_dataset.cache()\n",
    "    if train:\n",
    "        raw_dataset = raw_dataset.repeat()\n",
    "        raw_dataset = raw_dataset.shuffle(buffer_size=buffer_size)\n",
    "\n",
    "    dataset = raw_dataset.map(_parse_tfrecord(train, boxes), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(boxes, train=True, buffer_size=1024):\n",
    "    if train:\n",
    "        dataset = load_tfrecord_dataset(\n",
    "            tfrecord_name=TRAIN_TFRECORD_PATH,\n",
    "            train=train,\n",
    "            boxes=boxes,\n",
    "            buffer_size=buffer_size)\n",
    "    else:\n",
    "        dataset = load_tfrecord_dataset(\n",
    "            tfrecord_name=VALID_TFRECORD_PATH,\n",
    "            train=train,\n",
    "            boxes=boxes,\n",
    "            buffer_size=buffer_size)\n",
    "    return dataset\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PiecewiseConstantWarmUpDecay(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, boundaries, values, warmup_steps, min_lr, name=None):\n",
    "        super(PiecewiseConstantWarmUpDecay, self).__init__()\n",
    "\n",
    "        if len(boundaries) != len(values) - 1:\n",
    "            raise ValueError(\n",
    "                    \"The length of boundaries should be 1 less than the\"\n",
    "                    \"length of values\")\n",
    "\n",
    "        self.boundaries = boundaries\n",
    "        self.values = values\n",
    "        self.name = name\n",
    "        self.warmup_steps = warmup_steps\n",
    "        self.min_lr = min_lr\n",
    "\n",
    "    def __call__(self, step):\n",
    "        with tf.name_scope(self.name or \"PiecewiseConstantWarmUp\"):\n",
    "            step = tf.cast(tf.convert_to_tensor(step), tf.float32)\n",
    "            pred_fn_pairs = []\n",
    "            warmup_steps = self.warmup_steps\n",
    "            boundaries = self.boundaries\n",
    "            values = self.values\n",
    "            min_lr = self.min_lr\n",
    "\n",
    "            pred_fn_pairs.append(\n",
    "                (step <= warmup_steps,\n",
    "                 lambda: min_lr + step * (values[0] - min_lr) / warmup_steps))\n",
    "            pred_fn_pairs.append(\n",
    "                (tf.logical_and(step <= boundaries[0],\n",
    "                                step > warmup_steps),\n",
    "                 lambda: tf.constant(values[0])))\n",
    "            pred_fn_pairs.append(\n",
    "                (step > boundaries[-1], lambda: tf.constant(values[-1])))\n",
    "\n",
    "            for low, high, v in zip(boundaries[:-1], boundaries[1:],\n",
    "                                    values[1:-1]):\n",
    "                pred = (step > low) & (step <= high)\n",
    "                pred_fn_pairs.append((pred, lambda: tf.constant(v)))\n",
    "\n",
    "            return tf.case(pred_fn_pairs, lambda: tf.constant(values[0]),\n",
    "                           exclusive=True)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiStepWarmUpLR(initial_learning_rate, lr_steps, lr_rate,\n",
    "                      warmup_steps=0., min_lr=0.,\n",
    "                      name='MultiStepWarmUpLR'):\n",
    "    assert warmup_steps <= lr_steps[0]\n",
    "    assert min_lr <= initial_learning_rate\n",
    "    lr_steps_value = [initial_learning_rate]\n",
    "    for _ in range(len(lr_steps)):\n",
    "        lr_steps_value.append(lr_steps_value[-1] * lr_rate)\n",
    "    return PiecewiseConstantWarmUpDecay(\n",
    "        boundaries=lr_steps, values=lr_steps_value, warmup_steps=warmup_steps,\n",
    "        min_lr=min_lr)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_negative_mining(loss, class_truth, neg_ratio):\n",
    "    pos_idx = class_truth > 0\n",
    "    num_pos = tf.math.reduce_sum(tf.cast(pos_idx, tf.int32), axis=1)\n",
    "    num_neg = num_pos * neg_ratio\n",
    "\n",
    "    rank = tf.argsort(loss, axis=1, direction='DESCENDING')\n",
    "    rank = tf.argsort(rank, axis=1)\n",
    "    neg_idx = rank < tf.expand_dims(num_neg, 1)\n",
    "\n",
    "    return pos_idx, neg_idx\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultiBoxLoss(num_class, neg_pos_ratio=3.0):\n",
    "    def multi_loss(y_true, y_pred):\n",
    "        num_batch = tf.shape(y_true)[0]\n",
    "        loc_pred, class_pred = y_pred[..., :4], y_pred[..., 4:]\n",
    "        loc_truth, class_truth = y_true[..., :4], tf.squeeze(y_true[..., 4:])\n",
    "\n",
    "        cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "        temp_loss = cross_entropy(class_truth, class_pred)\n",
    "        pos_idx, neg_idx = hard_negative_mining(temp_loss, class_truth, neg_pos_ratio)\n",
    "\n",
    "        cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='sum')\n",
    "        loss_class = cross_entropy(\n",
    "            class_truth[tf.math.logical_or(pos_idx, neg_idx)],\n",
    "            class_pred[tf.math.logical_or(pos_idx, neg_idx)])\n",
    "        \n",
    "        smooth_l1_loss = tf.keras.losses.Huber(reduction='sum')\n",
    "        loss_loc = smooth_l1_loss(loc_truth[pos_idx],loc_pred[pos_idx])\n",
    "\n",
    "        num_pos = tf.math.reduce_sum(tf.cast(pos_idx, tf.float32))\n",
    "\n",
    "        loss_class = loss_class / num_pos\n",
    "        loss_loc = loss_loc / num_pos\n",
    "        return loss_loc, loss_class\n",
    "\n",
    "    return multi_loss\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = default_box()\n",
    "train_dataset = load_dataset(boxes, train=True)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SsdModel()\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(\n",
    "    model, \n",
    "    to_file=os.path.join(os.getcwd(), 'model.png'),\n",
    "    show_shapes=True, \n",
    "    show_layer_names=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = DATASET_LEN // BATCH_SIZE\n",
    "learning_rate = MultiStepWarmUpLR(\n",
    "    initial_learning_rate=1e-2,\n",
    "    lr_steps=[e*steps_per_epoch for e in [50, 70]],\n",
    "    lr_rate=0.1,\n",
    "    warmup_steps=5*steps_per_epoch,\n",
    "    min_lr=1e-4\n",
    ")\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
    "\n",
    "multi_loss = MultiBoxLoss(len(IMAGE_LABELS), neg_pos_ratio=3)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(inputs, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, training=True)\n",
    "        losses = {}\n",
    "        losses['reg'] = tf.reduce_sum(model.losses)  #unused. Init for redefine network\n",
    "        losses['loc'], losses['class'] = multi_loss(labels, predictions)\n",
    "        total_loss = tf.add_n([l for l in losses.values()])\n",
    "\n",
    "    grads = tape.gradient(total_loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    return total_loss, losses\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(0, EPOCHS):\n",
    "    for step, (inputs, labels) in enumerate(train_dataset.take(steps_per_epoch)):\n",
    "        load_t0 = time.time()\n",
    "        total_loss, losses = train_step(inputs, labels)\n",
    "        load_t1 = time.time()\n",
    "        batch_time = load_t1 - load_t0\n",
    "        print(f\"\\rEpoch: {epoch + 1}/{EPOCHS} | Batch {step + 1}/{steps_per_epoch} | Batch time {batch_time:.3f} || Loss: {total_loss:.6f} | loc loss:{losses['loc']:.6f} | class loss:{losses['class']:.6f} \",end = '',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nms(boxes, scores, nms_threshold=0.4, limit=200):\n",
    "    if boxes.shape[0] == 0:\n",
    "        return tf.constant([], dtype=tf.int32)\n",
    "    selected = [0]\n",
    "    idx = tf.argsort(scores, direction='DESCENDING')\n",
    "    idx = idx[:limit]\n",
    "    boxes = tf.gather(boxes, idx)\n",
    "\n",
    "    iou = _jaccard(boxes, boxes)\n",
    "\n",
    "    while True:\n",
    "        row = iou[selected[-1]]\n",
    "        next_indices = row <= nms_threshold\n",
    "\n",
    "        iou = tf.where(\n",
    "            tf.expand_dims(tf.math.logical_not(next_indices), 0),\n",
    "            tf.ones_like(iou, dtype=tf.float32),\n",
    "            iou\n",
    "        )\n",
    "\n",
    "        if not tf.math.reduce_any(next_indices):\n",
    "            break\n",
    "\n",
    "        selected.append(tf.argsort(\n",
    "            tf.dtypes.cast(next_indices, tf.int32), direction='DESCENDING')[0].numpy())\n",
    "\n",
    "    return tf.gather(idx, selected)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_bbox_tf(predicts, boxes, variances=[0.1, 0.2]):\n",
    "    centers = boxes[:, :2] + predicts[:, :2] * variances[0] * boxes[:, 2:]\n",
    "    sides = boxes[:, 2:] * tf.math.exp(predicts[:, 2:] * variances[1])\n",
    "    return tf.concat([centers - sides / 2, centers + sides / 2], axis=1)\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_predict(predictions, boxes):\n",
    "    label_classes = IMAGE_LABELS\n",
    "\n",
    "    bbox_predictions, confidences = tf.split(predictions[0], [4, -1], axis=-1)\n",
    "    boxes = decode_bbox_tf(bbox_predictions, boxes)\n",
    "\n",
    "    scores = tf.math.softmax(confidences, axis=-1)\n",
    "\n",
    "    out_boxes = []\n",
    "    out_labels = []\n",
    "    out_scores = []\n",
    "\n",
    "    for c in range(1, len(label_classes)):\n",
    "        cls_scores = scores[:, c]\n",
    "\n",
    "        score_idx = cls_scores > 0.5\n",
    "\n",
    "        cls_boxes = boxes[score_idx]\n",
    "        cls_scores = cls_scores[score_idx]\n",
    "\n",
    "        nms_idx = compute_nms(cls_boxes, cls_scores)\n",
    "\n",
    "        cls_boxes = tf.gather(cls_boxes, nms_idx)\n",
    "        cls_scores = tf.gather(cls_scores, nms_idx)\n",
    "\n",
    "        cls_labels = [c] * cls_boxes.shape[0]\n",
    "\n",
    "        out_boxes.append(cls_boxes)\n",
    "        out_labels.extend(cls_labels)\n",
    "        out_scores.append(cls_scores)\n",
    "\n",
    "    out_boxes = tf.concat(out_boxes, axis=0)\n",
    "    out_scores = tf.concat(out_scores, axis=0)\n",
    "\n",
    "    boxes = tf.clip_by_value(out_boxes, 0.0, 1.0).numpy()\n",
    "    classes = np.array(out_labels)\n",
    "    scores = out_scores.numpy()\n",
    "\n",
    "    return boxes, classes, scores\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_input_image(img, max_steps):\n",
    "    img_h, img_w, _ = img.shape\n",
    "\n",
    "    img_pad_h = 0\n",
    "    if img_h % max_steps > 0:\n",
    "        img_pad_h = max_steps - img_h % max_steps\n",
    "\n",
    "    img_pad_w = 0\n",
    "    if img_w % max_steps > 0:\n",
    "        img_pad_w = max_steps - img_w % max_steps\n",
    "\n",
    "    padd_val = np.mean(img, axis=(0, 1)).astype(np.uint8)\n",
    "    img = cv2.copyMakeBorder(img, 0, img_pad_h, 0, img_pad_w,\n",
    "                             cv2.BORDER_CONSTANT, value=padd_val.tolist())\n",
    "    pad_params = (img_h, img_w, img_pad_h, img_pad_w)\n",
    "\n",
    "    return img, pad_params\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_pad(boxes, pad_params):\n",
    "    img_h, img_w, img_pad_h, img_pad_w = pad_params\n",
    "    box = np.reshape(boxes[0], [-1, 2, 2]) * [(img_pad_w + img_w) / img_w, (img_pad_h + img_h) / img_h]\n",
    "    boxes[0] = np.reshape(box, [-1, 4])\n",
    "    return boxes\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_box_on_face(img, boxes, classes, scores, box_index, class_list):\n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "\n",
    "    x_min = int(boxes[box_index][0] * img_width)\n",
    "    y_min = int(boxes[box_index][1] * img_height)\n",
    "    x_max = int(boxes[box_index][2] * img_width)\n",
    "    y_max = int(boxes[box_index][3] * img_height)\n",
    "\n",
    "    if classes[box_index] == 1:\n",
    "        color = (0, 255, 0)\n",
    "    else:\n",
    "        color = (0, 0, 255)\n",
    "    cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color, 2)\n",
    "    \n",
    "    if len(scores) > box_index :\n",
    "        score = \"{:.4f}\".format(scores[box_index])\n",
    "        class_name = class_list[classes[box_index]]\n",
    "        label = '{} {}'.format(class_name, score)\n",
    "        position = (x_min, y_min - 4) \n",
    "        cv2.putText(img, label, position, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255))\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(PROJECT_PATH, 'checkpoints', 'weights_epoch_008.h5')\n",
    "model.load_weights(filepath)\n",
    "\n",
    "TEST_IMAGE_PATH = os.path.join(PROJECT_PATH, 'image_people.png')\n",
    "\n",
    "img_raw = cv2.imread(TEST_IMAGE_PATH)\n",
    "img_raw = cv2.resize(img_raw, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "img = np.float32(img_raw.copy())\n",
    "\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img, pad_params = pad_input_image(img, max_steps=max(BOX_STEPS))\n",
    "img = img / 255.0\n",
    "\n",
    "boxes = default_box()\n",
    "boxes = tf.cast(boxes, tf.float32)\n",
    "\n",
    "predictions = model.predict(img[np.newaxis, ...])\n",
    "\n",
    "pred_boxes, labels, scores = parse_predict(predictions, boxes)\n",
    "pred_boxes = recover_pad(pred_boxes, pad_params)\n",
    "\n",
    "for box_index in range(len(pred_boxes)):\n",
    "    draw_box_on_face(img_raw, pred_boxes, labels, scores, box_index, IMAGE_LABELS)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(img_raw, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
